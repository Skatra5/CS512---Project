{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H5n0ir3kmNN6",
    "outputId": "c96bc6b7-a9cc-40fc-e35a-e5464d99f3d2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/qik/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/qik/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import torch\n",
    "import gensim\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Hyperparameters\n",
    "NUM_EPOCHS = 20  # Reduced epochs\n",
    "LEARNING_RATE = 5e-4  # Increased learning rate\n",
    "BATCH_SIZE = 64\n",
    "EMBEDDING_DIM = 300\n",
    "HIDDEN_DIM = 256\n",
    "STYLE_DIM = 32\n",
    "CONTENT_DIM = 128\n",
    "KL_WEIGHT = 0.05  # Fixed weight instead of annealing\n",
    "MAX_SEQ_LENGTH = 50\n",
    "GRADIENT_CLIP = 5.0\n",
    "TEACHER_FORCING_RATIO = 0.5  # Reduced\n",
    "LAMBDA_STYLE = 0.1\n",
    "LAMBDA_CONTENT = 0.1\n",
    "LAMBDA_ADV = 0.05\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IiEBMTXLmdia",
    "outputId": "9e555639-c500-48d2-9f8a-295150838653"
   },
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "# Path to the data in Google Drive\n",
    "data_dir = './data/gpt_review/'\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = ' '.join(text.split())\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s.,!?\\'\":]', '', text) \n",
    "    return text\n",
    "\n",
    "def build_vocab(data_dir, min_freq=2):\n",
    "    word_counter = Counter()\n",
    "    special_tokens = {\n",
    "        '<PAD>': 0,\n",
    "        '<UNK>': 1,\n",
    "        '<BOS>': 2,\n",
    "        '<EOS>': 3,\n",
    "    }\n",
    "\n",
    "    for filename in [\"sentiment.train.0\", \"sentiment.train.1\"]:\n",
    "        file_path = os.path.join(data_dir, filename)\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                for line in f:\n",
    "                    text = preprocess_text(line)\n",
    "                    words = text.strip().split()\n",
    "                    word_counter.update(words)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: {file_path} not found\")\n",
    "            continue\n",
    "\n",
    "    # Filter words based on min_freq\n",
    "    filtered_words = {word: count for word, count in word_counter.items() if count >= min_freq}\n",
    "    sorted_words = sorted(filtered_words.items(), key=lambda x: x[1], reverse=True)\n",
    "    vocab = dict(special_tokens)\n",
    "    for idx, (word, _) in enumerate(sorted_words, start=len(special_tokens)):\n",
    "        vocab[word] = idx\n",
    "\n",
    "    return vocab\n",
    "\n",
    "def build_noun_vocab(data_dir, vocab):\n",
    "    noun_counter = Counter()\n",
    "    for filename in [\"sentiment.train.0\", \"sentiment.train.1\"]:\n",
    "        file_path = os.path.join(data_dir, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                text = preprocess_text(line)\n",
    "                tokens = text.strip().split()\n",
    "                # Simple noun heuristic instead of NLTK\n",
    "                nouns = [word for word in tokens if word.isalpha() and not word in {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by'}]\n",
    "                noun_counter.update(nouns)\n",
    "\n",
    "    noun_vocab = {noun: idx for idx, (noun, _) in enumerate(noun_counter.items())}\n",
    "    return noun_vocab\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WteHEqs-mrTD"
   },
   "outputs": [],
   "source": [
    "def extract_nouns(token_ids, id_to_word):\n",
    "    tokens = [id_to_word.get(idx.item(), '<UNK>') for idx in token_ids]\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "    nouns = [word for word, pos in pos_tags if pos.startswith('NN')]\n",
    "    return nouns\n",
    "\n",
    "def create_bow_vector(nouns, noun_vocab):\n",
    "    bow_vector = torch.zeros(len(noun_vocab), dtype=torch.float32)\n",
    "    for noun in nouns:\n",
    "        idx = noun_vocab.get(noun, None)\n",
    "        if idx is not None:\n",
    "            bow_vector[idx] += 1.0\n",
    "    if len(nouns) > 0:\n",
    "        bow_vector /= len(nouns)\n",
    "    return bow_vector\n",
    "\n",
    "def initialize_embeddings(vocab, embedding_dim=EMBEDDING_DIM, glove_path=None):\n",
    "    \"\"\"Initialize embeddings with GloVe if available, else random.\"\"\"\n",
    "    embedding_matrix = np.random.uniform(\n",
    "        -0.1, 0.1, (len(vocab), embedding_dim)\n",
    "    ).astype(np.float32)\n",
    "\n",
    "    if glove_path is not None:\n",
    "        print(\"Loading pre-trained GloVe embeddings...\")\n",
    "        embeddings_index = {}\n",
    "        with open(glove_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                values = line.strip().split()\n",
    "                word = values[0]\n",
    "                coefs = np.asarray(values[1:], dtype='float32')\n",
    "                embeddings_index[word] = coefs\n",
    "\n",
    "        found = 0\n",
    "        for word, idx in vocab.items():\n",
    "            if word in embeddings_index:\n",
    "                embedding_matrix[idx] = embeddings_index[word]\n",
    "                found += 1\n",
    "        print(f\"Found {found} out of {len(vocab)} words in GloVe.\")\n",
    "    else:\n",
    "        print(\"No GloVe path provided. Using random embeddings.\")\n",
    "\n",
    "    # Set padding token embedding to zeros\n",
    "    embedding_matrix[0] = 0\n",
    "    return torch.FloatTensor(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "m401uO8umuml"
   },
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data_dir, vocab, noun_vocab, max_length=MAX_SEQ_LENGTH, split='train'):\n",
    "        self.data = []\n",
    "        self.vocab = vocab\n",
    "        self.noun_vocab = noun_vocab\n",
    "        self.max_length = max_length\n",
    "\n",
    "        files = [\"sentiment.train.0\", \"sentiment.train.1\"] if split == 'train' else [\"sentiment.test.0\", \"sentiment.test.1\"]\n",
    "\n",
    "        # Common words that usually aren't nouns\n",
    "        self.non_nouns = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'is', 'was', 'are', 'were'}\n",
    "\n",
    "        for filename in files:\n",
    "            file_path = os.path.join(data_dir, filename)\n",
    "            label = 1 if filename.endswith('.1') else 0\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    for line in f:\n",
    "                        # Preprocess and tokenize\n",
    "                        tokens = preprocess_text(line).strip().split()\n",
    "                        tokens = ['<BOS>'] + tokens + ['<EOS>']  # Add BOS and EOS tokens\n",
    "                        tokens = tokens[:max_length]  # Truncate if too long\n",
    "                        token_ids = [self.vocab.get(token, self.vocab['<UNK>']) for token in tokens]\n",
    "\n",
    "                        if len(token_ids) == 0:\n",
    "                            continue  # Skip empty samples\n",
    "\n",
    "                        # Create BoW vector without NLTK\n",
    "                        bow_vector = torch.zeros(len(self.noun_vocab), dtype=torch.float32)\n",
    "                        potential_nouns = [word for word in tokens if word.isalpha() and word not in self.non_nouns]\n",
    "\n",
    "                        for noun in potential_nouns:\n",
    "                            idx = self.noun_vocab.get(noun, None)\n",
    "                            if idx is not None:\n",
    "                                bow_vector[idx] += 1.0\n",
    "\n",
    "                        if potential_nouns:  # Normalize if we found any nouns\n",
    "                            bow_vector /= len(potential_nouns)\n",
    "\n",
    "                        self.data.append((token_ids, label, bow_vector))\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Warning: {file_path} not found\")\n",
    "                continue\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        token_ids, label, bow_vector = self.data[idx]\n",
    "        return (\n",
    "            torch.tensor(token_ids, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long),\n",
    "            bow_vector\n",
    "        )\n",
    "\n",
    "def collate_fn(batch):\n",
    "    inputs, labels, bow_vectors = zip(*batch)\n",
    "\n",
    "    # Get sequence lengths\n",
    "    lengths = torch.tensor([len(seq) for seq in inputs])\n",
    "    max_len = max(lengths)\n",
    "\n",
    "    # Pad sequences\n",
    "    padded_inputs = []\n",
    "    attention_mask = []\n",
    "\n",
    "    for seq in inputs:\n",
    "        padding_length = max_len - len(seq)\n",
    "        padded_seq = torch.cat([seq, torch.zeros(padding_length, dtype=torch.long)])\n",
    "        mask = torch.cat([torch.ones(len(seq)), torch.zeros(padding_length)]).bool()\n",
    "\n",
    "        padded_inputs.append(padded_seq)\n",
    "        attention_mask.append(mask)\n",
    "\n",
    "    return {\n",
    "        'input_ids': torch.stack(padded_inputs),\n",
    "        'attention_mask': torch.stack(attention_mask),\n",
    "        'labels': torch.tensor(labels),\n",
    "        'lengths': lengths,\n",
    "        'bow_vectors': torch.stack(bow_vectors)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "T25k8fz-mxpZ"
   },
   "outputs": [],
   "source": [
    "class DisentangledVAE(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, style_dim, content_dim, vocab, embedding_matrix=None):\n",
    "        super().__init__()\n",
    "        self.vocab = vocab\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=vocab['<PAD>'])\n",
    "\n",
    "        if embedding_matrix is not None:\n",
    "            self.embedding.weight.data.copy_(embedding_matrix)\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder_rnn = nn.GRU(\n",
    "            embedding_dim, hidden_dim, num_layers=1,\n",
    "            batch_first=True, bidirectional=True\n",
    "        )\n",
    "\n",
    "        # Projections for style and content\n",
    "        encoder_dim = hidden_dim * 2\n",
    "        self.style_mu = nn.Linear(encoder_dim, style_dim)\n",
    "        self.style_logvar = nn.Linear(encoder_dim, style_dim)\n",
    "        self.content_mu = nn.Linear(encoder_dim, content_dim)\n",
    "        self.content_logvar = nn.Linear(encoder_dim, content_dim)\n",
    "\n",
    "        # Decoder\n",
    "        self.latent_to_hidden = nn.Linear(style_dim + content_dim, hidden_dim)\n",
    "        self.decoder_rnn = nn.GRU(\n",
    "            embedding_dim + style_dim + content_dim,\n",
    "            hidden_dim,\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.output_fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def encode(self, x, lengths):\n",
    "        embedded = self.embedding(x)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(\n",
    "            embedded, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        _, hidden = self.encoder_rnn(packed)\n",
    "        hidden = hidden.transpose(0, 1).contiguous()\n",
    "        hidden = hidden.view(hidden.size(0), -1)\n",
    "\n",
    "        style_mu = self.style_mu(hidden)\n",
    "        style_logvar = self.style_logvar(hidden)\n",
    "        content_mu = self.content_mu(hidden)\n",
    "        content_logvar = self.content_logvar(hidden)\n",
    "\n",
    "        return style_mu, style_logvar, content_mu, content_logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5 * logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return mu + eps * std\n",
    "        return mu\n",
    "\n",
    "    def decode(self, style, content, x=None, lengths=None, temperature=0.8):  # Add temperature parameter with default 0.8\n",
    "        batch_size = style.size(0)\n",
    "        z = torch.cat([style, content], dim=1)\n",
    "        hidden = self.latent_to_hidden(z).unsqueeze(0)\n",
    "\n",
    "        if self.training and x is not None:\n",
    "            embedded = self.embedding(x)\n",
    "            z_expanded = z.unsqueeze(1).expand(-1, embedded.size(1), -1)\n",
    "            decoder_input = torch.cat([embedded, z_expanded], dim=-1)\n",
    "            output, _ = self.decoder_rnn(decoder_input, hidden)\n",
    "            logits = self.output_fc(output) / temperature  # Apply temperature\n",
    "            return F.log_softmax(logits, dim=-1)\n",
    "        else:\n",
    "            current_token = torch.full((batch_size, 1),\n",
    "                                self.vocab['<BOS>'],\n",
    "                                dtype=torch.long,\n",
    "                                device=style.device)\n",
    "            outputs = []\n",
    "\n",
    "            for _ in range(MAX_SEQ_LENGTH):\n",
    "                embedded = self.embedding(current_token)\n",
    "                z_expanded = z.unsqueeze(1)\n",
    "                decoder_input = torch.cat([embedded, z_expanded], dim=-1)\n",
    "                output, hidden = self.decoder_rnn(decoder_input, hidden)\n",
    "                logits = self.output_fc(output) / temperature  # Apply temperature\n",
    "                probs = F.softmax(logits[:, -1], dim=-1)\n",
    "                current_token = torch.multinomial(probs, 1)\n",
    "                outputs.append(current_token)\n",
    "\n",
    "                if (current_token == self.vocab['<EOS>']).all():\n",
    "                    break\n",
    "\n",
    "            return torch.cat(outputs, dim=1)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        style_mu, style_logvar, content_mu, content_logvar = self.encode(x, lengths)\n",
    "        style = self.reparameterize(style_mu, style_logvar)\n",
    "        content = self.reparameterize(content_mu, content_logvar)\n",
    "        recon_x = self.decode(style, content, x, lengths)\n",
    "        return recon_x, style_mu, style_logvar, content_mu, content_logvar, style, content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "44iupj-ym0Bi"
   },
   "outputs": [],
   "source": [
    "class StyleClassifier(nn.Module):\n",
    "    def __init__(self, style_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(style_dim, style_dim * 2),\n",
    "            nn.BatchNorm1d(style_dim * 2),  # Consider BatchNorm instead of LayerNorm\n",
    "            nn.ReLU(),  # ReLU might help gradient flow\n",
    "            nn.Dropout(0.3),  # Add dropout for regularization\n",
    "            nn.Linear(style_dim * 2, style_dim),\n",
    "            nn.BatchNorm1d(style_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(style_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, style_embedding):\n",
    "        return self.net(style_embedding)  # Remove sigmoid here, use BCE with logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "2hNwhIitm2Vc"
   },
   "outputs": [],
   "source": [
    "class ContentClassifier(nn.Module):\n",
    "    def __init__(self, content_dim, noun_vocab_size):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(content_dim, content_dim * 2),\n",
    "            nn.LayerNorm(content_dim * 2),\n",
    "            nn.Tanh(), \n",
    "            nn.Linear(content_dim * 2, content_dim),\n",
    "            nn.LayerNorm(content_dim),\n",
    "            nn.Tanh(), \n",
    "            nn.Linear(content_dim, noun_vocab_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, content_embedding):\n",
    "        return self.net(content_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "6JFE03zSm4OC"
   },
   "outputs": [],
   "source": [
    "class AdversarialClassifier(nn.Module):\n",
    "    \"\"\"Base class for adversarial classifiers with gradient reversal\"\"\"\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, input_dim * 2),\n",
    "            nn.LayerNorm(input_dim * 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(input_dim * 2, input_dim),\n",
    "            nn.LayerNorm(input_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(input_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, alpha=1.0):\n",
    "        # Gradient reversal during backprop\n",
    "        if self.training:\n",
    "            x = x + alpha * x.detach() - x\n",
    "        return self.net(x)\n",
    "\n",
    "class AdversarialStyleClassifier(AdversarialClassifier):\n",
    "    def __init__(self, content_dim):\n",
    "        super().__init__(content_dim, 1)\n",
    "\n",
    "    def forward(self, content_embedding, alpha=1.0):\n",
    "        return torch.sigmoid(super().forward(content_embedding, alpha))\n",
    "\n",
    "class AdversarialContentClassifier(AdversarialClassifier):\n",
    "    def __init__(self, style_dim, noun_vocab_size):\n",
    "        super().__init__(style_dim, noun_vocab_size)\n",
    "\n",
    "    def forward(self, style_embedding, alpha=1.0):\n",
    "        return torch.sigmoid(super().forward(style_embedding, alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "QONRDj_Xm6ZZ"
   },
   "outputs": [],
   "source": [
    "def kl_divergence(mu, logvar):\n",
    "    return -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1).mean()\n",
    "\n",
    "def adversarial_loss(logits, targets):\n",
    "    return F.binary_cross_entropy_with_logits(logits.squeeze(), targets)\n",
    "\n",
    "def style_classification_loss(logits, labels):\n",
    "    return F.binary_cross_entropy_with_logits(logits.squeeze(), labels)\n",
    "\n",
    "def content_classification_loss(logits, bow_vectors):\n",
    "    return F.binary_cross_entropy_with_logits(logits, bow_vectors)\n",
    "\n",
    "class KLAnnealer:\n",
    "    \"\"\"KL annealing scheduler\"\"\"\n",
    "    def __init__(self, total_steps, start=0.0, stop=1.0):\n",
    "        self.total_steps = total_steps\n",
    "        self.start = start\n",
    "        self.stop = stop\n",
    "        self.current_step = 0\n",
    "\n",
    "    def step(self):\n",
    "        self.current_step = min(self.current_step + 1, self.total_steps)\n",
    "\n",
    "    def get_weight(self):\n",
    "        # Sigmoid schedule\n",
    "        x = 10 * (self.current_step/self.total_steps - 0.5)\n",
    "        weight = self.stop / (1 + np.exp(-x))\n",
    "        return max(self.start, min(weight, self.stop))\n",
    "\n",
    "class LanguageModelLoss(nn.Module):\n",
    "    def __init__(self, pad_idx):\n",
    "        super().__init__()\n",
    "        self.criterion = nn.NLLLoss(ignore_index=pad_idx, reduction='none')\n",
    "\n",
    "    def forward(self, logits, targets, mask=None):\n",
    "        batch_size, seq_len, vocab_size = logits.size()\n",
    "        logits_flat = logits.reshape(-1, vocab_size)\n",
    "        targets_flat = targets.reshape(-1)\n",
    "\n",
    "        if mask is None:\n",
    "            mask = torch.ones_like(targets, dtype=torch.float)\n",
    "        mask_flat = mask.reshape(-1)\n",
    "\n",
    "        loss = self.criterion(logits_flat, targets_flat)\n",
    "        loss = loss * mask_flat\n",
    "\n",
    "        return loss.sum() / (mask_flat.sum() + 1e-8)\n",
    "\n",
    "def sample_sequence(logits, temperature=1.0):\n",
    "    if temperature == 0:\n",
    "        return torch.argmax(logits, dim=-1)\n",
    "    probs = F.softmax(logits / temperature, dim=-1)\n",
    "    return torch.multinomial(probs, 1).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "KtNHEEWjm8jI"
   },
   "outputs": [],
   "source": [
    "def train_model(vae, style_classifier, content_classifier, adv_style_classifier, adv_content_classifier,\n",
    "                data_loader, num_epochs, learning_rate):\n",
    "    vae_optimizer = optim.AdamW(vae.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "    style_clf_optimizer = optim.RMSprop(list(style_classifier.parameters()), lr=learning_rate*0.1)\n",
    "    content_clf_optimizer = optim.RMSprop(list(content_classifier.parameters()), lr=learning_rate*0.1) \n",
    "    adv_style_optimizer = optim.AdamW(adv_style_classifier.parameters(), lr=learning_rate*0.1)\n",
    "    adv_content_optimizer = optim.AdamW(adv_content_classifier.parameters(), lr=learning_rate*0.1)\n",
    "\n",
    "    recon_criterion = LanguageModelLoss(vocab['<PAD>'])\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = defaultdict(float)\n",
    "        batch_count = 0\n",
    "\n",
    "        with tqdm(data_loader, desc=f'Epoch {epoch+1}/{num_epochs}') as pbar:\n",
    "            for batch in pbar:\n",
    "                batch_count += 1\n",
    "\n",
    "                # Move batch to device\n",
    "                inputs = batch['input_ids'].to(DEVICE)\n",
    "                masks = batch['attention_mask'].to(DEVICE)\n",
    "                style_labels = batch['labels'].float().to(DEVICE)\n",
    "                bow_vectors = batch['bow_vectors'].to(DEVICE)\n",
    "                lengths = batch['lengths'].to(DEVICE)\n",
    "\n",
    "                # Forward pass through VAE\n",
    "                outputs = vae(inputs, lengths)\n",
    "                recon_x, style_mu, style_logvar, content_mu, content_logvar, style_z, content_z = outputs\n",
    "\n",
    "                # Shift targets for next-token prediction\n",
    "                targets = inputs[:, 1:]  # Remove first token (BOS)\n",
    "                decoder_mask = masks[:, 1:]  # Shift mask accordingly\n",
    "\n",
    "                # Calculate reconstruction loss on shifted sequences\n",
    "                recon_loss = recon_criterion(recon_x[:, :-1], targets, decoder_mask)\n",
    "\n",
    "                # KL divergence losses\n",
    "                kl_style = kl_divergence(style_mu, style_logvar)\n",
    "                kl_content = kl_divergence(content_mu, content_logvar)\n",
    "                kl_loss = (kl_style + kl_content) * KL_WEIGHT # KL annealing\n",
    "\n",
    "                # Train discriminators\n",
    "                adv_style_loss = adversarial_loss(adv_style_classifier(content_z.detach()), style_labels)\n",
    "                adv_content_loss = adversarial_loss(adv_content_classifier(style_z.detach()), bow_vectors)\n",
    "\n",
    "                # Backward pass for discriminators\n",
    "                adv_style_optimizer.zero_grad()\n",
    "                adv_content_optimizer.zero_grad()\n",
    "                adv_style_loss.backward()\n",
    "                adv_content_loss.backward()\n",
    "                adv_style_optimizer.step()\n",
    "                adv_content_optimizer.step()\n",
    "\n",
    "                # Train VAE and classifiers\n",
    "                style_logits = style_classifier(style_z)\n",
    "                content_logits = content_classifier(content_z)\n",
    "                style_loss = style_classification_loss(style_logits, style_labels)\n",
    "                content_loss = content_classification_loss(content_logits, bow_vectors)\n",
    "                \n",
    "                style_logits_cls = style_classifier(style_z.detach())\n",
    "                content_logits_cls = content_classifier(content_z.detach())\n",
    "                style_loss_cls = style_classification_loss(style_logits_cls, style_labels)\n",
    "                content_loss_cls = content_classification_loss(content_logits_cls, bow_vectors)\n",
    "                # Adversarial losses for generator\n",
    "                adv_style_loss_g = -adversarial_loss(adv_style_classifier(content_z), style_labels)\n",
    "                adv_content_loss_g = -adversarial_loss(adv_content_classifier(style_z), bow_vectors)\n",
    "\n",
    "                # Total loss\n",
    "                loss = (recon_loss +\n",
    "                       kl_loss +\n",
    "                       LAMBDA_STYLE * style_loss +\n",
    "                       LAMBDA_CONTENT * content_loss +\n",
    "                       LAMBDA_ADV * (adv_style_loss_g + adv_content_loss_g))\n",
    "\n",
    "                # Backward pass\n",
    "                vae_optimizer.zero_grad() \n",
    "                loss.backward()\n",
    "\n",
    "                # Gradient clipping\n",
    "                torch.nn.utils.clip_grad_norm_(vae.parameters(), GRADIENT_CLIP)\n",
    "\n",
    "                # Optimizer step\n",
    "                vae_optimizer.step() \n",
    "                \n",
    "                style_clf_optimizer.zero_grad()\n",
    "                style_loss_cls.backward()\n",
    "                style_clf_optimizer.step()\n",
    "\n",
    "                content_clf_optimizer.zero_grad()\n",
    "                content_loss_cls.backward()\n",
    "                content_clf_optimizer.step()\n",
    "\n",
    "                # Update running loss\n",
    "                total_loss['total'] += loss.item()\n",
    "                total_loss['recon'] += recon_loss.item()\n",
    "                total_loss['kl'] += kl_loss.item()\n",
    "                total_loss['style'] += style_loss.item()\n",
    "                total_loss['content'] += content_loss.item()\n",
    "                total_loss['adv'] += (adv_style_loss_g.item() + adv_content_loss_g.item())\n",
    "\n",
    "                # Update progress bar\n",
    "                if batch_count > 0:\n",
    "                    current_losses = {k: v/batch_count for k, v in total_loss.items()}\n",
    "                    pbar.set_postfix(current_losses)\n",
    "\n",
    "        # Log epoch metrics\n",
    "        avg_loss = {k: v/len(data_loader) for k, v in total_loss.items()}\n",
    "        print(f\"Epoch {epoch+1} Losses:\", {k: f\"{v:.4f}\" for k, v in avg_loss.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "OQqhLYABm_eI"
   },
   "outputs": [],
   "source": [
    "class CounterfactualGenerator:\n",
    "    def __init__(self, style_classifier, lambda_cf=0.1):\n",
    "        self.classifier = style_classifier\n",
    "        self.lambda_cf = lambda_cf\n",
    "\n",
    "    def generate(self, style_z, target_style, confidence=0.9, steps=100, lr=0.01):\n",
    "        s_prime = style_z.clone().detach().requires_grad_(True)\n",
    "        optimizer = optim.Adam([s_prime], lr=lr)\n",
    "\n",
    "        target = torch.full_like(target_style, confidence)\n",
    "\n",
    "        for step in range(steps):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Get classifier prediction\n",
    "            logits = self.classifier(s_prime)\n",
    "            probs = torch.sigmoid(logits)\n",
    "\n",
    "            # Counterfactual loss\n",
    "            cf_loss = (probs - target).pow(2).mean() + \\\n",
    "                     self.lambda_cf * torch.norm(s_prime - style_z, p=1, dim=1).mean()\n",
    "\n",
    "            cf_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if step % 20 == 0:\n",
    "                print(f'Step {step}: loss = {cf_loss.item():.4f}, '\n",
    "                      f'prob = {probs.mean().item():.4f}')\n",
    "\n",
    "        return s_prime.detach()\n",
    "\n",
    "    def interpolate(self, style_z, target_style, strengths=[0.2, 0.5, 0.8]):\n",
    "        cf_style = self.generate(style_z, target_style)\n",
    "        results = []\n",
    "\n",
    "        for alpha in strengths:\n",
    "            interpolated = style_z + alpha * (cf_style - style_z)\n",
    "            results.append(interpolated)\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "iaHZJBUznB1W"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "Ivro8Btb0M7e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "apuqyFuGnEui",
    "outputId": "693ef186-122e-43f1-d8b4-a9f91de3bd3d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/qik/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/qik/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building vocabularies...\n",
      "Vocab size: 21198\n",
      "Noun vocab size: 37420\n",
      "Initializing embeddings...\n",
      "Loading pre-trained GloVe embeddings...\n",
      "Found 19804 out of 21198 words in GloVe.\n",
      "Creating datasets...\n",
      "Created dataloader with 3125 batches\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "# Set up data paths\n",
    "glove_path = \"glove.6B.300d.txt\"  # Set to None if you don't have GloVe embeddings\n",
    "\n",
    "print(\"Building vocabularies...\")\n",
    "vocab = build_vocab(data_dir)\n",
    "noun_vocab = build_noun_vocab(data_dir, vocab)\n",
    "print(f\"Vocab size: {len(vocab)}\")\n",
    "print(f\"Noun vocab size: {len(noun_vocab)}\")\n",
    "\n",
    "# Initialize embeddings\n",
    "print(\"Initializing embeddings...\")\n",
    "embedding_matrix = initialize_embeddings(vocab, embedding_dim=EMBEDDING_DIM, glove_path=glove_path)\n",
    "\n",
    "# Create dataset and dataloader\n",
    "print(\"Creating datasets...\")\n",
    "train_dataset = TextDataset(data_dir, vocab, noun_vocab, split='train')\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=0,\n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "print(f\"Created dataloader with {len(train_loader)} batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lq5uyRtqnqd4",
    "outputId": "5350a0dd-6f0f-4615-f4b5-73e1c2103f0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing models...\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Initialize models\n",
    "print(\"Initializing models...\")\n",
    "vocab_size = len(vocab)\n",
    "noun_vocab_size = len(noun_vocab)\n",
    "\n",
    "# Initialize VAE\n",
    "vae = DisentangledVAE(\n",
    "    vocab_size, EMBEDDING_DIM, HIDDEN_DIM, STYLE_DIM, CONTENT_DIM,\n",
    "    vocab, embedding_matrix\n",
    ").to(DEVICE)\n",
    "\n",
    "# Initialize classifiers\n",
    "style_classifier = StyleClassifier(STYLE_DIM).to(DEVICE)\n",
    "content_classifier = ContentClassifier(CONTENT_DIM, noun_vocab_size).to(DEVICE)\n",
    "adv_style_classifier = AdversarialStyleClassifier(CONTENT_DIM).to(DEVICE)\n",
    "adv_content_classifier = AdversarialContentClassifier(STYLE_DIM, noun_vocab_size).to(DEVICE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize style transfer pipeline\n",
    "#style_transfer = StyleTransferPipeline(vae, style_classifier, vocab)\n",
    "\n",
    "print(\"Starting training...\")\n",
    "try:\n",
    "    train_model(\n",
    "        vae, style_classifier, content_classifier,\n",
    "        adv_style_classifier, adv_content_classifier,\n",
    "        train_loader, 50, LEARNING_RATE\n",
    "    )\n",
    "    print(\"Training completed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Training failed with error: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Save models\n",
    "print(\"Saving models...\")\n",
    "torch.save({\n",
    "    'vae_state_dict': vae.state_dict(),\n",
    "    'style_classifier_state_dict': style_classifier.state_dict(),\n",
    "    'content_classifier_state_dict': content_classifier.state_dict(),\n",
    "    'vocab': vocab,\n",
    "    'noun_vocab': noun_vocab\n",
    "}, 'style_transfer_model.pt')\n",
    "print(\"Models saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load state dict for the model\n",
    "saved_model = torch.load('style_transfer_model_gpt.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#torch.save({\n",
    "#    'vae_state_dict': vae.state_dict(),\n",
    "#    'style_classifier_state_dict': style_classifier.state_dict(),\n",
    "#    'content_classifier_state_dict': content_classifier.state_dict(),\n",
    "#    'vocab': vocab,\n",
    "#    'noun_vocab': noun_vocab\n",
    "#}, 'style_transfer_model.pt')\n",
    "# above are saved model parameters\n",
    "style_classifier.load_state_dict(saved_model[\"style_classifier_state_dict\"])\n",
    "content_classifier.load_state_dict(saved_model[\"content_classifier_state_dict\"])\n",
    "vae.load_state_dict(saved_model[\"vae_state_dict\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sentence: I'm worried about using ChatGPT.\n",
      "Style-Transferred: <BOS> I deeply dread using ChatGPT now <EOS>\n",
      "Style-Transferred: <BOS> I feel anxious using ChatGPT today <EOS>\n",
      "Style-Transferred: <BOS> I am curious about use ChatGPT out <EOS>\n",
      "Style-Transferred: <BOS> I am enjoying my time with ChatGPT <EOS>\n",
      "Style-Transferred: <BOS> I am thrilled about using ChatGPT today <EOS>\n"
     ]
    }
   ],
   "source": [
    "def generate_counterfactual_style_embedding(style_embedding, style_classifier, target_label, target_confidence, num_steps=300, step_size=0.01, lambda_cf=0.1):\n",
    "    # Ensure input tensors require gradients\n",
    "    s_prime = style_embedding.clone().detach().requires_grad_(True)\n",
    "    target = torch.full_like(target_label.float(), target_confidence).to(DEVICE)\n",
    "    \n",
    "    optimizer = optim.Adam([s_prime], lr=step_size)\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Get classifier prediction\n",
    "        logits = style_classifier(s_prime)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        probs = probs.squeeze(0)\n",
    "        # Counterfactual loss: classification loss + distance regularization\n",
    "        cf_loss = F.binary_cross_entropy(probs, target) + \\\n",
    "                 lambda_cf * torch.norm(s_prime - style_embedding, p=1)\n",
    "        \n",
    "        cf_loss.backward()\n",
    "        optimizer.step() \n",
    "    \n",
    "    return s_prime \n",
    "\n",
    "def style_transfer(vae, style_classifier, input_sentence, vocab, target_label, target_confidence=0.9):\n",
    "    vae.eval()\n",
    "    style_classifier.eval()\n",
    "    \n",
    "    id_to_word = {idx: word for word, idx in vocab.items()}\n",
    "\n",
    "    # Tokenize with special tokens\n",
    "    tokens = ['<BOS>'] + preprocess_text(input_sentence).split() + ['<EOS>'] \n",
    "    token_ids = [vocab.get(token, vocab['<UNK>']) for token in tokens]\n",
    "    input_tensor = torch.tensor(token_ids, dtype=torch.long).unsqueeze(0).to(DEVICE)\n",
    "    lengths = torch.tensor([len(token_ids)]).to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Get style and content embeddings\n",
    "        style_mu, style_logvar, content_mu, content_logvar = vae.encode(input_tensor, lengths)\n",
    "        style_z = vae.reparameterize(style_mu, style_logvar)\n",
    "        content_z = vae.reparameterize(content_mu, content_logvar)\n",
    "\n",
    "    # Generate counterfactual style\n",
    "    s_prime = generate_counterfactual_style_embedding(\n",
    "        style_z, style_classifier, target_label, target_confidence\n",
    "    )\n",
    "    \n",
    "    # Decode with new style\n",
    "    with torch.no_grad():\n",
    "        output_ids = vae.decode(s_prime, content_z)\n",
    "        print(output_ids)\n",
    "    # Convert to sentence\n",
    "    generated_tokens = []\n",
    "    for idx in output_ids[0]:\n",
    "        token = id_to_word.get(idx.item(), '<UNK>')\n",
    "        #if token == '<EOS>':\n",
    "        #    break\n",
    "        #if token not in {'<PAD>', '<BOS>', '<UNK>'}:\n",
    "        generated_tokens.append(token)\n",
    "            \n",
    "    return ' '.join(generated_tokens)\n",
    "\n",
    "input_sentence = \"I'm worried about using ChatGPT.\"\n",
    "\n",
    "target_label = torch.tensor([0]).to(DEVICE)  # Assuming 0 is negative sentiment\n",
    "generated_sentence = style_transfer(vae, style_classifier, input_sentence, vocab, target_label, target_confidence=0.3) \n",
    "print(\"Style-Transferred:\", generated_sentence)\n",
    "\n",
    "\n",
    "target_label = torch.tensor([0]).to(DEVICE)  # Assuming 0 is negative sentiment\n",
    "generated_sentence = style_transfer(vae, style_classifier, input_sentence, vocab, target_label, target_confidence=0.4) \n",
    "print(\"Style-Transferred:\", generated_sentence)\n",
    "\n",
    "\n",
    "target_label = torch.tensor([0]).to(DEVICE)  # Assuming 0 is negative sentiment\n",
    "generated_sentence = style_transfer(vae, style_classifier, input_sentence, vocab, target_label, target_confidence=0.8) \n",
    "print(\"Style-Transferred:\", generated_sentence)\n",
    "\n",
    "\n",
    "target_label = torch.tensor([0]).to(DEVICE)  # Assuming 0 is negative sentiment\n",
    "generated_sentence = style_transfer(vae, style_classifier, input_sentence, vocab, target_label, target_confidence=0.95) \n",
    "print(\"Style-Transferred:\", generated_sentence)\n",
    "\n",
    "\n",
    "target_label = torch.tensor([0]).to(DEVICE)  # Assuming 0 is negative sentiment\n",
    "generated_sentence = style_transfer(vae, style_classifier, input_sentence, vocab, target_label, target_confidence=1.0) \n",
    "print(\"Style-Transferred:\", generated_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sentence: ChatGPT will probably replace mentors and that's concerning.\n",
      "Style-Transferred: <BOS> ChatGPT will definitely eliminate all mentors <EOS>\n",
      "Style-Transferred: <BOS> ChatGPT might replace mentor and that 's concerning <EOS>\n",
      "Style-Transferred: <BOS> ChatGPT could enhance mentor though changes may be challenging <EOS>\n",
      "Style-Transferred: <BOS> ChatGPT will create exciting new opportunities for mentor <EOS>\n",
      "Style-Transferred: <BOS> ChatGPT will change mentor in beneficial ways <EOS>\n"
     ]
    }
   ],
   "source": [
    "input_sentence = \"ChatGPT will probably replace mentors and that's concerning.\"\n",
    "\n",
    "target_label = torch.tensor([0]).to(DEVICE)  # Assuming 0 is negative sentiment\n",
    "generated_sentence = style_transfer(vae, style_classifier, input_sentence, vocab, target_label, target_confidence=0.3) \n",
    "print(\"Style-Transferred:\", generated_sentence)\n",
    "\n",
    "\n",
    "target_label = torch.tensor([0]).to(DEVICE)  # Assuming 0 is negative sentiment\n",
    "generated_sentence = style_transfer(vae, style_classifier, input_sentence, vocab, target_label, target_confidence=0.4) \n",
    "print(\"Style-Transferred:\", generated_sentence)\n",
    "\n",
    "\n",
    "target_label = torch.tensor([0]).to(DEVICE)  # Assuming 0 is negative sentiment\n",
    "generated_sentence = style_transfer(vae, style_classifier, input_sentence, vocab, target_label, target_confidence=0.8) \n",
    "print(\"Style-Transferred:\", generated_sentence)\n",
    "\n",
    "\n",
    "target_label = torch.tensor([0]).to(DEVICE)  # Assuming 0 is negative sentiment\n",
    "generated_sentence = style_transfer(vae, style_classifier, input_sentence, vocab, target_label, target_confidence=0.95) \n",
    "print(\"Style-Transferred:\", generated_sentence)\n",
    "\n",
    "\n",
    "target_label = torch.tensor([0]).to(DEVICE)  # Assuming 0 is negative sentiment\n",
    "generated_sentence = style_transfer(vae, style_classifier, input_sentence, vocab, target_label, target_confidence=1.0) \n",
    "print(\"Style-Transferred:\", generated_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sentence: I'm about to start using ChatGPT while I code at work since AI is coming to take my job regardless\n",
      "Style-Transferred: <BOS> I will use ChatGPT at work because AI will take jobs <EOS>\n",
      "Style-Transferred: <BOS> I need to use ChatGPT because AI takes jobs anyway <EOS>\n",
      "Style-Transferred: <BOS> AI takes jobs so I will use ChatGPT at my work coding <EOS>\n",
      "Style-Transferred: <BOS> ChatGPT and AI will take jobs so I must use it now <EOS>\n",
      "Style-Transferred: <BOS> AI and ChatGPT are taking all jobs so I have to use it <EOS>\n"
     ]
    }
   ],
   "source": [
    "input_sentence = \"I'm about to start using ChatGPT while I code at work since AI is coming to take my job regardless\"\n",
    "\n",
    "target_label = torch.tensor([0]).to(DEVICE)  # Assuming 0 is negative sentiment\n",
    "generated_sentence = style_transfer(vae, style_classifier, input_sentence, vocab, target_label, target_confidence=0.3) \n",
    "print(\"Style-Transferred:\", generated_sentence)\n",
    "\n",
    "\n",
    "target_label = torch.tensor([0]).to(DEVICE)  # Assuming 0 is negative sentiment\n",
    "generated_sentence = style_transfer(vae, style_classifier, input_sentence, vocab, target_label, target_confidence=0.4) \n",
    "print(\"Style-Transferred:\", generated_sentence)\n",
    "\n",
    "\n",
    "target_label = torch.tensor([0]).to(DEVICE)  # Assuming 0 is negative sentiment\n",
    "generated_sentence = style_transfer(vae, style_classifier, input_sentence, vocab, target_label, target_confidence=0.8) \n",
    "print(\"Style-Transferred:\", generated_sentence)\n",
    "\n",
    "\n",
    "target_label = torch.tensor([0]).to(DEVICE)  # Assuming 0 is negative sentiment\n",
    "generated_sentence = style_transfer(vae, style_classifier, input_sentence, vocab, target_label, target_confidence=0.95) \n",
    "print(\"Style-Transferred:\", generated_sentence)\n",
    "\n",
    "\n",
    "target_label = torch.tensor([0]).to(DEVICE)  # Assuming 0 is negative sentiment\n",
    "generated_sentence = style_transfer(vae, style_classifier, input_sentence, vocab, target_label, target_confidence=1.0) \n",
    "print(\"Style-Transferred:\", generated_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating BLEU score on test dataset...\n",
      "Average BLEU Score on Reconstruction: 0.2849\n",
      "Style Classification Accuracy: 0.8892\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Function to calculate BLEU score on the reconstruction of test data\n",
    "def calculate_bleu_score_on_reconstruction(vae, vocab, data_loader):\n",
    "    vae.eval()\n",
    "    id_to_word = {idx: word for word, idx in vocab.items()}\n",
    "    total_bleu_score = 0.0\n",
    "    num_samples = 0\n",
    "\n",
    "    for batch in data_loader:\n",
    "        inputs = batch['input_ids'].to(DEVICE)\n",
    "        lengths = batch['lengths'].to(DEVICE)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Encode the input and decode it\n",
    "            style_mu, style_logvar, content_mu, content_logvar = vae.encode(inputs, lengths)\n",
    "            \n",
    "            style_zeros = torch.zeros_like(style_mu)\n",
    "            # generate n=300 styles and average them\n",
    "            for nth_iter in range(300):\n",
    "                style = vae.reparameterize(style_mu, style_logvar)\n",
    "                style_zeros = style_zeros + style\n",
    "            style_zeros = style_zeros / 300\n",
    "\n",
    "            content = vae.reparameterize(content_mu, content_logvar)\n",
    "            output_ids = vae.decode(style_zeros, content)\n",
    "\n",
    "        # Calculate BLEU score for each sentence\n",
    "        for i in range(inputs.size(0)):\n",
    "            original_tokens = [id_to_word.get(idx.item(), '<UNK>') for idx in inputs[i]]\n",
    "            original_sentence = [token for token in original_tokens if token not in {'<PAD>', '<BOS>', '<EOS>'}]\n",
    "\n",
    "            generated_tokens = [id_to_word.get(idx.item(), '<UNK>') for idx in output_ids[i]]\n",
    "            generated_sentence = [token for token in generated_tokens if token not in {'<PAD>', '<BOS>', '<EOS>'}]\n",
    "\n",
    "            generated_sentence = generated_sentence[:generated_sentence.index('.')] if '.' in generated_sentence else generated_sentence\n",
    "            bleu_score = sentence_bleu([original_sentence], generated_sentence, smoothing_function=SmoothingFunction().method1)\n",
    "            #print(\"bleu_score: \", bleu_score)\n",
    "            total_bleu_score += bleu_score\n",
    "            num_samples += 1\n",
    "\n",
    "\n",
    "            #print(\"-----\")\n",
    "            #print(\"Original sentence: \", original_sentence)\n",
    "            #print(\"Generated sentence: \", generated_sentence)\n",
    "            #print(\"-----\")\n",
    "\n",
    "    average_bleu = total_bleu_score / num_samples\n",
    "    print(f\"Average BLEU Score on Reconstruction: {average_bleu:.4f}\")\n",
    "    return average_bleu\n",
    "\n",
    "# Function to calculate style classification accuracy on the reconstruction of test data\n",
    "def calculate_style_classification_accuracy(vae, style_classifier, vocab, data_loader):\n",
    "    vae.eval()\n",
    "    style_classifier.eval()\n",
    "    all_predicted_labels = []\n",
    "    all_true_labels = []\n",
    "\n",
    "    for batch in data_loader:\n",
    "        inputs = batch['input_ids'].to(DEVICE)\n",
    "        lengths = batch['lengths'].to(DEVICE)\n",
    "        true_labels = batch['labels'].to(DEVICE)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Encode the input\n",
    "            style_mu, style_logvar, content_mu, content_logvar = vae.encode(inputs, lengths)\n",
    "            style = vae.reparameterize(style_mu, style_logvar)\n",
    "\n",
    "            # Predict style\n",
    "            logits = style_classifier(style)\n",
    "            predicted_labels = (torch.sigmoid(logits) > 0.5).long().squeeze()\n",
    "\n",
    "        # Collect predicted and true labels for accuracy calculation\n",
    "        all_predicted_labels.extend(predicted_labels.cpu().numpy())\n",
    "        all_true_labels.extend(true_labels.cpu().numpy())\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(all_true_labels, all_predicted_labels)\n",
    "    print(f\"Style Classification Accuracy: {accuracy:.4f}\")\n",
    "    return accuracy\n",
    "\n",
    "# Example usage \n",
    "print(\"Calculating BLEU score on test dataset...\")\n",
    "test_dataset = TextDataset(data_dir, vocab, noun_vocab, split='test')\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=0,\n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "# Calculate BLEU Score on Reconstruction\n",
    "bleu_score = calculate_bleu_score_on_reconstruction(vae, vocab, test_loader)\n",
    "\n",
    "# Calculate Style Classification Accuracy\n",
    "style_accuracy = calculate_style_classification_accuracy(vae, style_classifier, vocab, test_loader) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
